\documentclass{article}
%==============================================================================%
%	                          Packages                                     %
%==============================================================================%
% Packages
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}
\usepackage[margin=0.7in]{geometry}
\usepackage[version=4]{mhchem}
%==============================================================================%
%                           User-Defined Commands                              %
%==============================================================================%
% User-Defined Commands
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\benum}{\begin{enumerate}}
\newcommand{\eenum}{\end{enumerate}}
\newcommand{\pd}{\partial}
\newcommand{\dg}{\dagger}
%==============================================================================%
%                             Title Information                                %
%==============================================================================%
\title{Chem237: Lecture 3}
\date{4/5/18}
\author{Alan Robledo, Shane Flynn, Moises Romero}
%==============================================================================%
%	Everyone Please Make Comments if Something Needs to be Reviewed        %
%                           Or just fix it yourself!                           %
%==============================================================================%
\begin{document}
\maketitle
\section*{Stuff}
One of the many Ordinary Differential Equations (ODEs) which have an analytical solution is Clairaut's equation.
In general, it has the form
\be \label{eq:clair}
y - x y' = f(y')
\ee
where f is a continuosuly differentiable function of the derivative of y with respect to (wrt) x.
To solve it, we start by taking the derivative wrt x of both sides, which involves using the product rule and the chain rule.
\be
\frac{d}{dx} (y - x y') = \frac{d}{dx}f(y') \Rightarrow y' - y' - xy'' = \frac{df}{dy'} \frac{dy'}{dx} = f'(y') y''
\Rightarrow -xy'' = f'(y') y''
\ee
While every other prime is meant to be a derivative wrt x, do not forget that $f'(y') = \frac{df(y')}{dy'}$ because it is easy to mistake this for $f'(y') \neq \frac{df(y')}{dx}$ at later times.
Now, moving the $-xy''$ term to the other side gives us
\be
y''(f'(y') + x) = 0
\ee
and by inspection, we can get two solutions to the ODE.
\be
\begin{split}
f'(y') + x &= 0 \\
y'' &= 0
\end{split}
\ee
The bottom equation has a solution that can be found with two simple integrations
\be
\int y'' dx = \int 0 dx \Rightarrow y' = a \Rightarrow \\
\int y' dx = \int a dx \Rightarrow y = ax + b
\ee
where a and b are arbitrary constants.
If we take the y and y' we found and substitute them back into equation (\ref{eq:clair}), we get
\be
ax + b - ax = f(a) \Rightarrow b = f(a)
\ee
Thus, y = ax + f(a) is a general solution.
However, we also have $f'(y') + x = 0$.
Using this and equation (\ref{eq:clair}), we have two equations with two unknowns, y and y'.
We could use one of the equations to eliminate y' from the other equation and end up with a closed form solution for y.
Such a solution would have no arbitrary constants and is therefore called the singular solution.

To get a better understanding of this, let's consider an example equation
\be
y = x y' + (y')^2
\ee
We can see that this a Clairaut equation because we can subtract $xy'$ from both sides and $(y')^2$ can be considered a function of y'.
Taking from the general case, we can say that $f(a) = a^2$ where a is an arbitrary constant, giving us a general solution.
\be
y = ax + a^2
\ee
However, we also have to consider the equation
\be
f'(y') + x = \frac{d}{y'} (y')^2 + x = 2y' + x = 0.
\ee
If we solve for y' and substitute into equation (\ref{eq:clair}), we get
\be
y = -\frac{x^2}{2} + \frac{x^2}{4} = -\frac{x^2}{4}
\ee
which is our singular solution since it has no arbitrary constants like the general solution.
The singular solution has a nice property, in that it is an envelope to a family of curves defined by the general solution.
This means that, when plotted, every possible general solution is tangential to the singular solution (see figure 1).
% Add plot of singular solution and a few different general solutions here.
\begin{enumerate}
  \centering
  \item $P(x) y'' + Q(x) y' + R(x) y = S(x)$
  \item $P(x) y'' + Q(x) y' + R(x) y = 0$
\end{enumerate}
\be
  y = u_1(x) y_1(x) + u_2(x) y_2(x)
\ee
\be
  u'_1 y_1 + u'_2 y_2 = 0
\ee
\be
\begin{split}
  y' &= u'_1 y_1 + u_1 y'_1 + u'_2 y_2 + u_2 y'_2 \\
  &= u_1 y'_1 + u_2 y'_2
\end{split}
\ee
\be
  y'' = u'_1 y'_1 + u_1 y''_1 + u'_2 y'_2 + u_2 y''_2
\ee
\be
  P(x) [u'_1 y'_1 + u_1 y''_1 + u'_2 y'_2 + u_2 y''_2] + Q(x) [u_1 y'_1 + u_2 y'_2] + R(x) [u_1 y_1 + u_2 y_2] = S(x)
\ee
\be
\begin{split}
  P(x) [u'_1 y'_1 & + u'_2 y'_2] + P(x)u_1(x) y''_1 + Q(x) u_1(x) y'_1 + R(x) u_1(x) y_1 + \\
  & P(x) u_2(x) y''_2 + Q(x) u_2(x) y'_2 + R(x) u_2(x) y_2 = S(x)
\end{split}
\ee
Since $P(x)u_1(x)$, $Q(x)u_1(x)$, $R(x)u_1(x), P(x)u_2(x)$, $Q(x)u_2(x)$, $R(x)u_2(x)$ are all arbitrary functions of x and y$_1$ and y$_2$ are solutions to (2) in equation (whatever), we can say
\be
\begin{split}
  & P(x)u_1(x) y''_1 + Q(x) u_1(x) y'_1 + R(x) u_1(x) y_1 = 0\\
  & P(x) u_2(x) y''_2 + Q(x) u_2(x) y'_2 + R(x) u_2(x) y_2 = 0
\end{split}
\ee
which leaves us with
\be
  P(x) [u'_1 y'_1 + u'_2 y'_2] = S(x)
\ee
Using our constraint from before, we can make a system of linear equations
\be
\begin{split}
  P(x) y'_1 u'_1 + P(x) y'_2 u'_2 &= S(x) \\
  y_1 u'_1 + y_2 u'_2 &= 0
\end{split}
\ee
where the only unkonwns are u'$_1$ and u'$_2$.
After solving for the unknowns, both can be integrated with respect to x to obtain u$_1$, u$_2$ and thus the solution to the inhomogenous equation.
Example
\begin{enumerate}
  \centering
  \item $x^2 y'' - 2y = x$
  \item $x^2 y'' - 2y = 0$
\end{enumerate}
Noting that $y = x^m$ is a natural guess for the solution to (2), we can obtain a general solution by plugging it and its derivatives
\be
\begin{split}
  y &= x^m \\
  y' &= m x^{m-1} \\
  y'' &= m(m-1)x^{m-2}
\end{split}
\ee
into (2) and dividing by $x^m$ to obtain the characteristic ploynomial
\be
m(m-1) x^2 x^{m-2} - 2 x^m = 0 \Rightarrow m(m-1) - 2 = 0 \Rightarrow m^2 - m - 2 = 0
\ee
whose solutions are $m = 2$ and $m = -1$, so the general solution is the linear combination of unique solutions.
\be
y = c_1 x^2 + \frac{c_2}{x}
\ee
Just as before, let's assume that the solution to the inhomogenous equation is of the form
\be
y = u_1(x) x^2 + u_2(x) \Big( \frac{1}{x} \Big)
\ee
Now we can take derivatives to plug into the original ODE, while keeping in mind the constraint $u'_1 y_1 + u'_2 y_2 = 0$.
\be
\begin{split}
  y' &= u'_1 x^2 + 2 u_1 x  + u'_2 \Big( \frac{1}{x} \Big) - u_2 \Big( \frac{1}{x^2} \Big) = 2u_1 x - u_2 \Big( \frac{1}{x^2} \Big) \\
  y'' &= 2 u'_1 x + 2u_1 - u'_2 \Big( \frac{1}{x^2} \Big) + u_2 \Big( \frac{2}{x^3} \Big)
\end{split}
\ee
If we plug y and y'' into (1), we get
\be
  x^2 \Big[ 2 u'_1 x + 2u_1 - u'_2 \Big( \frac{1}{x^2} \Big) + u_2 \Big( \frac{2}{x^3} \Big) \Big] - 2 \Big[ u_1 x^2 + u_2 \Big( \frac{1}{x} \Big) \Big] = x
\ee
and with some rearranging
\be
2x^3 u'_1 - u'_2 + 2x^2 u_1 + 2u_2 \Big( \frac{1}{x} \Big) - 2u_1 x^2 - 2u_2 \Big(\frac{1}{x} \Big) = x
\ee
we obtain
\be
2x^3 u'_1 - u'_2 = x
\ee
And since we are left with u'$_1$ and u'$_2$, we can make our system of linear equations with the equation above and our constraint.
\be
\begin{split}
  2x^3 u'_1 - u'_2 &= x \\
  x^2 u'_1 + \Big( \frac{1}{x} \Big) u'_2 &= 0
\end{split}
\ee
We can solve the system by solving the above equation for u'$_2$ and plugging it into the equation below to solve for u'$_1$
\be
x^2u'_1 + \Big( \frac{1}{x} \Big) \Big( 2x^3 u'_1 - x \Big) = 0 \Rightarrow u'_1( x^2 + 2x^2) - 1 = 0 \Rightarrow u'_1 = \frac{1}{3x^2}
\ee
Plugging u'$_1$ into the equation above gives us u'$_2$
\be
2x^3 \Big( \frac{1}{3x^2} \Big) - u'_2 = x \Rightarrow \frac{2}{3}x - u'_2 = x \Rightarrow u'_2 = - \frac{x}{3}
\ee
Integrating both u'$_1$ and u'$_2$ with respect to x gives
\be
\begin{split}
  \int u'_1 dx &= \int \frac{1}{3x^2} dx \Rightarrow u_1 = - \frac{1}{3x} + c_1 \\
  \int u'_2 dx &= \int - \frac{x}{3} dx \Rightarrow u_2 = - \frac{x^2}{6} + c_2
\end{split}
\ee
So the general solution to the inhomogenoues ODE is
\be
\begin{split}
y = \Big( - \frac{1}{3x} & + c_1 \Big) x^2 + \Big( - \frac{x^2}{6} + c_2 \Big) \frac{1}{x} \Rightarrow \\
& y = - \frac{x}{2} + c_1 x^2 + \frac{c_2}{x}
\end{split}
\ee
The last trick we will discuss involves second-order linear ODEs of the form
\be
y'' + f(x)y' + g(x)y = 0
\ee
Making the substitution $y = v(x)p(x)$, where p(x) is one solution to the ODE, will give us
\be
\begin{split}
(v''p & + v'p' + v'p' + vp'') + f(x)[v'p + vp'] + g(x)[vp] = 0 \Rightarrow \\
& pv'' + [2p' + f(x)p]v' + [p'' + f(x)p' + g(x)p]v = 0
\end{split}
\ee
Noting that p is a solution to the ODE, you can see that the expression inside the brackets of the third term is equal to zero.
Thus, after dividing by p, reducing the equation to a second-order ODE in v
\be
v'' + (2 \frac{p'}{p} + f)v' = 0
\ee
Solving for p becomes trivial after performing a \textbf{reduction of order}, which involves substituting $v'(x) = h(x)$ and $v''(x) = h'(x)$ into the ODE, which turns the second-order ODE in v into a first-order ODE in h.
Once you solve the first-order ODE, you can back-substitute h for v', integrate one last time to obtain v, and multiply your solution by p to obtain the general solution y.
\section*{Series}
Chapter 2 discusses tests for convergence of series and methods to determine the sum of a series.
% Needs a better intro.
Any ordered list of elements can be considered a \textbf{sequence}.
If we have a sequence of numbers, real or complex, this could be written as
\be
  a_1, a_2, \hdots, a_n
\ee
where n is the total amount of numbers (elements) in the sequence.

A \textbf{series} is defined as the summation of a sequence of numbers
\be
S=\sum_{n=1}^{\infty} a_n
\ee
A \textbf{partial sum} is defined as the summation of parts of sequence:
\be
S_N = \sum_{n=1}^{N} a_n
\ee
So it goes without saying that the infinte limit of a partial sum defines the infinite sum.
\be
S = \lim_{N \to \infty}{S_N} = \lim_{N \to \infty} \sum_{n=1}^{N} a_n
\ee
The value of S determines whether the series is labeled as convergent or divergent.
\subsection*{Convergence and Divergence}
A series $\sum\limits_{n=1}^{\infty} a_n$ is said to be \textbf{convergent} if its partial sums S$_1$, S$_2$, $\hdots$ tend towards some finite number.
If the partial sums tend towards $+\infty$ or $-\infty$, then the series is said to be \textbf{divergent}.
In other words, if
\be
\lim_{n \to \infty}{a_n} = 0
\ee
then the series is convergent.
If the limit is any other value or the limit does not exist, then the series is divergent.

If the series
\be
\sum_{n=1}^{\infty} |a_n|
\ee
converges to some finite value, then we say that $\sum\limits_{n=1}^{\infty} a_n$ is \textbf{absolutely convergent}.
If the series in equation (add number) diverges but $\sum\limits_{n=1}^{\infty} a_n$ is convergent, then we say that $\sum\limits_{n=1}^{\infty} a_n$ is \textbf{conditionally convergent}.
A very useful property of an absolutely convergent series is that any rearrangement of the terms that make up the original sum will always give the same sum.
On the other hand, any rearrangement of the terms that make up a conditionally convergent series will always give a different result for the sum.

For example, consider the alternating harmonic series:
\be
\sum_{n=1}^{\infty} a_n = \sum_{n = 1}^{\infty} \frac{(-1)^{n+1}}{n} = 1 - \frac{1}{2} + \frac{1}{3} - \hdots
\ee
This is an example of an alternating series because each successive term switches between a positive and negative sign.
Note: the $(-1)^{n+1}$ could be $(-1)^{n}$ or any other integer exponent and the series would still be considered an alternating series.
This series is said to be convergent and there are several tests that can be used to prove that this is true, some of which will be discussed later in the lecture.
In the infinite limit, the series converges to
\be
\sum_{n = 1}^{\infty} \frac{(-1)^{n+1}}{n} = \ln(2)
\ee
A quick way to prove this is to consider the following function
\be
S(x) = \sum_{n = 1}^{\infty} (-1)^{n+1} \frac{x^n}{n}
\ee
If we insert $x = 1$, we get back the alternating harmonic series.
And if you take a look at your list of every conceivable taylor expansion in the universe, you will find
\be
S(x) = \sum_{n = 1}^{\infty} (-1)^{n+1} \frac{x^n}{n} = \ln(1+x)
\ee
Since we know that our original series is equal to S(x) when x = 1, then we can say that the oringial series is equal to ln(2).
% Somebody find a better place to put the proof for ln(2), or add more flow.
However, the harmonic series
\be
\sum_{n=1}^{\infty} |a_n| = \sum_{n = 1}^{\infty} \frac{1}{n} = 1 + \frac{1}{2} + \frac{1}{3} + \hdots
\ee
is a well-known divergent series.
Therefore, from our properties mentioned earlier, we can say that the alternating harmonic series is conditionally convergent and not absolutely convergent.
If we consider rearranging the plus and minus signs in the alternating harmonic series, you can show that the infinite sum does not evaluate to ln(2),
\be
\sum_{n = 1}^{\infty} \frac{(-1)^{n}}{n} = -1 + \frac{1}{2} - \frac{1}{3} + \hdots = -\ln(2)
\ee
which is expected because the series is conditionally convergent.
On a side note, despite the harmonic series being divergent, we can show that the partial sums converge to:
\be
S_N = \sum_{n=1}^{N} \frac{1}{n} \approx \frac{1}{N}
\ee
% Somebody find the proof for above. I'm sure its easy to find.
Another well-known series is the geometric series:
\be
\sum_{n=0}^{\infty} a x^n = a + ax + ax^2 + \hdots
\ee
where a and x can be any real number.
Consider the case where a = 1, so the series and partial sum looks like
\be
\sum_{n=0}^{\infty} x^n = 1 + x + x^2 + \hdots \quad \text{and} \quad S_N = \sum_{n=0}^{N} x^n
\ee
If we wanted to know the value of the partial sum, we would need to know how the partial sums S$_N$ and S$_{N+1}$ are related.
Since we have two unknowns, that means we need two equations.
The first equation comes from noticing that each successive partial sum is equal to the previous partial sum plus the next term in the series.
\be
S_{N+1} = S_N + x^{N+1}
\ee
The other equation comes from noticing that
\be
\begin{split}
1 + x(1 + x + x^2 + \hdots + x^N) &= 1 + x + x^2 + x^3 + \hdots + x^{N+1} \\
1 + x (S_N) &= S_{N+1}
\end{split}
\ee
So we can define a system of linear equations as
\be
\begin{split}
S_{N+1} - S_N &= x^{N+1} \\
1 + xS_N &= S_{N+1}
\end{split}
\ee
and solve for S$_N$ by plugging in S$_{N+1}$ and rearranging to get
\be
S_N = \frac{1-x^{N+1}}{1-x}
\ee
If $|x| < 1$, we can show that the infinte sum converges
\be
S = \lim_{N \to \infty}S_N = \frac{1}{1-x}
\ee
and if $|x|\geq$ 1, then the series diverges.
\section*{Convergence tests}
\subsubsection*{D'Alembert-Lauche test}
Often referred to as the 'ratio test', if you have any series $\sum\limits_{n=1}^{\infty} a_n$, you can check whether it is absolutely convergent or divergent by evaluating the infinite limit of the ratio between a$_{n+1}$ and a$_n$
\be
\lim_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big|
\ee
\begin{itemize}
  \item If $\lim\limits_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big| < 1$, the series is absolutely convergent.
  \item If $\lim\limits_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big| > 1$, the series is divergent.
  \item If $\lim\limits_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big| = 1$, the test is inconclusive and another test should be used instead.
\end{itemize}
\subsubsection*{Integral Test}
Convergence of a series $\sum\limits_{n=1}^{\infty} f(n)$, where f(n) is continuous, can be determined by determining convergence of the definite integral.
\be
\int_{1}^{\infty}f(x)dx
\ee
Notice that the upper and lower limits of the definite integral are the same as the upper and lower limits of the series.
Note: the integral test does not determine whether a series is absolutely or conditionally convergent.

Using these two tests, we can test the Riemann Zeta (RZ) function for convergence.
For those who have not heard of the RZ function, it is defined as
\be
\zeta(s) = \sum_{n=1}^{\infty} \frac{1}{n^s} = 1 + \frac{1}{2^s} + \frac{1}{3^s}+ \hdots
\ee
where s is an integer.
Using the ratio test, we first need to evaluate the limit.
\begin{align}
\lim_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big| &= \lim_{n \to \infty} \frac{\frac{1}{(n+1)^s}}{\frac{1}{n^s}} = \lim_{n \to \infty} \Big( \frac{n}{n+1} \Big) ^s
= \lim_{n \to \infty} \Big( \frac{n+1}{n} \Big) ^{-s} = \lim_{n \to \infty} \Big( 1 + \frac{1}{n} \Big) ^{-s} \\
&= \lim_{n \to \infty} \exp \Big[ \ln \Big( 1 + \frac{1}{n} \Big) ^{-s} \Big] = \lim_{n \to \infty} \exp \Big[ (-s) \ln \Big( 1 + \frac{1}{n} \Big) \Big] \\
\end{align}
We can taylor expand to make the substitution $\ln(1 + \frac{1}{n}) = \frac{1}{n} - \frac{1}{2}(\frac{1}{n})^2 + \hdots \approx \frac{1}{n}$.
\be
\lim_{n \to \infty} \Big| \frac{a_{n+1}}{a_n} \Big| = \lim_{n \to \infty} \exp \Big[ (-s) \ln \Big( 1 + \frac{1}{n} \Big) \Big] \approx \lim_{n \to \infty} \exp \Big[ \frac{-s}{n} \Big]
\ee
Taylor expanding $\text{exp} \Big[ \frac{-s}{n} \Big]$ gives
\be
\lim_{n \to \infty} \exp \Big[ \frac{-s}{n} \Big] = \lim_{n \to \infty} 1 - \frac{s}{n} + \frac{1}{2} \Big( \frac{-s}{n} \Big)^2 + \hdots \approx \lim_{n \to \infty} 1 - \frac{s}{n} = 1
\ee
which means that the ratio test is inconclusive. So we can try the integral test.
\be
\int_{1}^{\infty} \frac{1}{x^s} dx = \frac{-1}{(s-1)(x^{s-1})} \Big\vert_{1}^{\infty}
\ee
So if s $>$ 1, the series is convergent and if s $<$ 1, the series is divergent.
\subsubsection*{Alternating Series Test}
As the name implies, this test is only to be used when you have an alternating series, e.g. $\sum\limits_{n=1}^{\infty} (-1)^n a_n$.
Any series of this form is considered convergent if:
\begin{enumerate}
  \item $\lim_{n \to \infty} a_n = 0$
  \item $|a_n| > |a_{n+1}|$
\end{enumerate}
If these conditions cannot be met, the series is considered divergent.
Using the alternating harmonic series as an example, we can check the two conditions and see that
\be
\lim_{n \to \infty} \frac{1}{n} = 0 \quad \text{and} \quad \frac{1}{n} > \frac{1}{n+1}
\ee
which shows that the series is convergent, as expected.
However, this test is not enough to show whether an alternating series is absolutely or conditionally convergent.
There are a few other tests that you could use such as the limit comparison test, p-series test, etc, but the three we went over are very useful on their own for testing convergence.
\end{document}
