\documentclass{article}
%==============================================================================%
%	                          Packages                                     %
%==============================================================================%
% Packages
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}
\usepackage[margin=0.7in]{geometry}
\usepackage[version=4]{mhchem}
%==============================================================================%
%                           User-Defined Commands                              %
%==============================================================================%
% User-Defined Commands
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\benum}{\begin{enumerate}}
\newcommand{\eenum}{\end{enumerate}}
\newcommand{\pd}{\partial}
\newcommand{\dg}{\dagger}
%==============================================================================%
%                             Title Information                                %
%==============================================================================%
\title{Chem237: Lecture 2}
\date{4/4/18}
\author{Shane Flynn,Moises Romero}
%==============================================================================%
%	Everyone Please Make Comments if Something Needs to be Reviewed        %
%                           Or just fix it yourself!                           %
%==============================================================================%
\begin{document}
\maketitle
\section*{ODE; Variable Coefficients}
We can now consider ODEs with variable coefficients.
Unfortunately most variable coefficient ODEs cannot be solved analytically, except for certain special cases. 

\subsection*{Variable Coefficients; Homogenous}
\be \label{eq:vc_homo}
\frac{dx}{dt} + a(t) x = 0
\ee
Cosider the linear, first order variable coefficient ODE above. 
This example is trivial because the problem is seperable, and can easily be solved by direct integration.
\be
\begin{split}
    \frac{dx}{dt} + &a(t) x = 0 \\
    \int dx \frac{1}{x} &= -\int dt \text{ a}(t) \\
    \ln(x) -\ln(x_0)  &= -\int dt \text{ a}(t) \\
    \ln(x)  = \ln(x_0) &-\int dt \text{ a}(t) \\
    x(t) = x_0 &\exp\left[-\int_{t_0}^t dt \text{ a}(t)\right] + c
\end{split}
\ee
The last line represents the homogeneous solution to the first order variable coefficient ODE (equation \ref{eq:vc_homo}).
Although the final answer is in terms of an integral, an integral is in general simpler than a differential equation to solve.
We therefore call this a solution, because we have made some progress. 

\subsubsection*{Differentials and Algebra}
A quick side note that is worth mentioning.
Solving a seperable differential equations (as we did above) seems to imply that the differential operators can be treated as algebraic elements (it looks like we just multiplied by dt in the above example).
Although this is convenient it is not `legitimate', and we should probably prove it works for these seperable equations.
Consider a simple differential equation
\be \label{eq:dif_alg}
\begin{split}
    f(y) \frac{dy}{dx} &= g(x)\\
    \int dx f(y) \frac{dy}{dx} &= \int dx g(x)
\end{split}
\ee
If we let F(y) define the anti-derivitive of f(y), meaning
\be
F(y) = \int f(y) dy \qquad \Rightarrow \qquad F'(y) = f(y)
\ee
Applying the chain rule to F(y) we find
\be
\frac{d}{dx} F(y) = f(y) \frac{dy}{dx}
\ee
We can now substitute in the chain rule into Equation \ref{eq:dif_alg} and we see find
\be
\begin{split}
    \int dx F'(y) &= \int dx g(x)\\
    F(y) &= \int dx g(x) \\
    \int f(y) dy &= \int dx g(x)
\end{split}
\ee
So we are not actually treating the operators algebraically, we can naturally re-arrange the equation through the chain rule.
This result is true for the specific equation we analyzed, although most people will solve seperable ODEs by pretending the operators are algebraic elements, it is good to realize why this machiney works in this context (and you should not assume it will work for differnt problems). 

\subsection*{Variable Coefficients; Non-Homogenous}
%==============================================================================%
%	I am here -Shane 4-27-18
%==============================================================================%
Now consider the non-homonogeous variable coefficient differential equation
\be \label{eq:vc_non}
\frac{dx}{dt} + a(t) x = f(t)
\ee
Where f(t) is a known (given) function.
We know the general solution to any non-homogenous equation is the summation of a particular solution (x$_p$), and the homogeneous equation.
Using the solution we found to Equation \ref{eq:vc_homo}, we can construct the solution to Equation \ref{eq:vc_non}.
\be
\begin{split}
    x(t) &= x_p(t) + x_0 e^{-A(t)}\\
    A(t) & \equiv \int_{t_0}^t dt \text{ a}(t)
\end{split}
\ee

A decent guess for the form of the particular solution is an expotential function multiplied by some other function.
The original differential equation relates a function and its derivitive, therefore the expotential is a good candidate.
And we need the particular solution to tell us something new, so we hope we can hope to oslve for somoe other function to describe the system. 
So let's assume the particular solution is of the form
\be
x_p(t) = e^{-A(t)}g(t)
\ee

Where g(t) is some unknown function that we can try to solve for. 
\be
\begin{split}
    \frac{dx_p(t)}{dt} + a(t) x_p(t) &= f(t) \Rightarrow \\
    \frac{d}{dt} e^{-A(t)}g(t) + a(t)  e^{-A(t)}g(t) &= f(t)\\
    e^{-A(t)} \frac{d}{dt} g(t) + g(t) \frac{d}{dt} e^{-A(t)} + a(t)  e^{-A(t)}g(t) &= f(t)\\
    e^{-A(t)} \frac{d}{dt} g(t) -a(t) e^{-A(t)} g(t) + a(t)  e^{-A(t)}g(t) &= f(t)\\
    e^{-A(t)} \frac{d}{dt} g(t) &= f(t) \Rightarrow \\
    g(t) &= \int^t dt \text{ }e^{A(t)} f(t) \Rightarrow \\
\end{split}
\ee

\section*{NonLinear ODE}
We will start a new, more complicated problem, the nonlinear ordinary differential equations.
There is no general solution to solve a non-linear ODE, however, there are classes that can be solved.

Consider first a generalized form for the first order ODE
\be
\begin{split}
    a(x) dx + b(y) dy &= 0 \Rightarrow\\
    b(y) \frac{dy}{dx} + a(x) &= 0
\end{split}
\ee
These two lines are equivalent, but the second line is much more convenient because it is separable and can be solved by integration.
This is the simplest form of a non-linear equation, because there isn't a y dependence in every term.

An even more general form would be
\be
A(x,y)dx + B(x,y)dy = 0
\ee
We will see that this is a more preferable form.

If this is an exact differential (the LHS), calling it U, then consider
\be
U(x,y), \quad dU(x,y) = Adx + Bdy
\ee
With both of these statements the solution is then
\be
U(x,y) + c = 0
\ee
So if we have an exact differential, than if we just find the exact differential than we can get the solution.

Consider exact differentials (the second line we simply give the partial derivatives names).
\be
\begin{split}
    dU &= \frac{\pd U}{\pd x} dx + \frac{\pd U}{\pd y} dy \\
    dU &= A dx + B dy \\
    \frac{\pd ^2 U}{\pd x \pd y} &= \frac{\pd ^2 U}{\pd y \pd x}
\end{split}
\ee
And the last line is a requirement for a total differential.

So we have seen that if we have an exact differential we can solve, and we have conditions that must be satisfied.

As an example consider
\be
\begin{split}
(2x+y)dx + (x+3y^2)dy &= 0 \\
A(x,y) & = 2x+y  \\
\frac{\partial A}{\partial y} &= 1 \\
B(x,y) & = x+ 3y^2  \\
\frac{\partial B}{\partial x} &= 1 \\
\end{split}
\ee
\be
\begin{split}
    \frac{\pd ^2 U}{\pd x \pd y} &= 1\\
    \frac{\pd ^2 U}{\pd y \pd x} &= 1\\
    U(x,y) &= x^2 + xy + y^3\\
\end{split}
\ee
We see this is an exact differential, therefore the solution to the problem is given  by
\be
x^2 + xy + y^3 + C = 0
\ee
%==============================================================================%
%	                Not exactly sure which method to use to reach the final conclusion             %
%==============================================================================%
\subsection*{Integrating Factor}
If we do not have an exact differential the problem is no longer easy, we have a few methods we can use to solve.
A well known method for addressing a non-linear ODE with is the \textbf{Integrating Factor}.
Consider Adx + Bdy, such that it is not an exact differntial.
Introduce the integrating factor $\lambda$(x,y), such that
\be
dU = \lambda(Adx + Bdy)
\ee
Is now transformed into an exact differential.
We therefore need to find a $\lambda$ such that the inexact differential becomes exact.A theorem exists stating that an integrating factor always exists!
\subsubsection*{Proof}
The proof for this theorem is as follows consider the above example :
\be
\begin{split}
A(x,y)dx + B(x,y)dy &= 0 \\
\frac{dy}{dx} &= -\frac{A}{B}
\end{split}
\ee
Which has a general solution of :
\be
f(x,y) = C
\ee
C is a constant. We then take a total differential:
\be
\begin{split}
\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y} dy &= 0 \\
\frac{dy}{dx} &=  - \frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial y}}\\
\end{split}
\ee
Relating the two we can see :
\be
\begin{split}
   \frac{dy}{dx} &=  - \frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial y}}= -\frac{A}{B}\\
   \frac{\frac{\partial f}{\partial x}}{A} &= \frac{\frac{\partial f}{\partial y}}{B}
\end{split}
\ee
We can then relate this ratio using a factor , which is the integrating factor $\lambda(x,y)$ :
\be
\begin{split}
\frac{\partial f}{\partial x} &= \lambda A  \\
\frac{\partial f}{\partial y} &= \lambda B
\end{split}
\ee
We multiply are general differential equation by an integrating factor as follows :
\be
\lambda A dx + \lambda B dy = 0
\ee
Unfortunately there is no general method for finding it, but $\lambda$ always exists!
There are known forms for A and B that we can recognize to solve for the integrating factor. As an example consider:
\be
y' + f(x) y = g(x) \Rightarrow dy + f(x) y dx = g(x) dx
\ee
We can always consider an integrating factor
\be
\lambda \left[dy + f(x) y dx\right] = \lambda g(x) dx
\ee
The idea is now to integrate each side, however, this will only be useful if the RHS is only a function of x.
If it turns out that $\lambda \rightarrow \lambda(x)$ than the RHS is always a function of x.
If $\lambda$(x,y) than we may not be able to solve the LHS.
%==============================================================================%
%	                May need to elaborate on this part, not sure
%==============================================================================%
So we will assume $\lambda \rightarrow \lambda(x)$ and see if it works.
The whole point of the method is to get an exact differential, therefore assume the LHS is exact.
\be
\frac{\pd\lambda}{\pd x} = \frac{\pd (\lambda f y)}{\pd y} = \lambda(x) f(x)
\ee
This new equation is separable and we can solve by integration.
\be
\int d\lambda \frac{1}{\lambda} = \int dx f(x) \Rightarrow \lambda(x) = \exp\left[\int dx f(x)\right]
\ee
So we see that we can find the integrating factor with $\lambda(x)$.
Now that we have an exact differential we need to confirm
\be
\begin{split}
    dU &\equiv \lambda(dy + f(x)ydx)\\
    \frac{\pd U}{\pd x} &= \lambda\\
    U(x,y) = \lambda(x) y
\end{split}
\ee
So we can solve this problem by integration, and find a general equation for any f(x), g(x). Another example consider
\be
\begin{split}
    xy' + (1+x) y = e^x \Rightarrow y' + \left(\frac{1+x}{x}\right)y &= \frac{e^x}{x}\\
    \lambda(x) = \exp\left[ \int dx \frac{1+x}{x} \right] = xe^x
\end{split}
\ee
Now if we multiply the LHS and RHS by $\lambda$
\be
\int xe^x\left[y' + \frac{1+x}{x} y\right] = \int dx e^{2x} \Rightarrow U(x,y) = xe^xy = \frac{1}{2} e^{2x} + c \Rightarrow y = \frac{e^x}{2x} + \frac{c}{x} e^{-x}
\ee

So we see that a non-linear first order ODE can be solved with the integrating factor method.
If we have an equation of the form
\be
y' + f(x)y = g(x)
\ee
Than the integrating factor is a useful approach, using a non-trivial transformation to generate a simple solution.

\subsection*{New Method}
We can look at other classes of equations we can solve for.
\be
A(x,y)dx + B(x,y)dy = 0
\ee
Consider an equation of the above from with A and B both being homogeneous functions of degree r.
Recall a homogeneous function obeys
\be
A(cx,cy) = c^r A(x,y)
\ee

As an example
\be
A = x^2 + yx, \qquad B = y^2
\ee
Both functions are homogeneous functions of degree 2.

For this type of equation for we can generate a separable equation through the substitution
\be
y = vx
\ee
Consider our example above we find
\be
ydx + (2\sqrt{xy} - x) dy = 0
\ee
In this example r=1, let y=vx and substitute in dy = vdx + xdv (assume an exact differential).
\be
vxdx + (2x\sqrt{v} - x) (vdx + xdv) = 0 \Rightarrow \frac{2\sqrt{v}-1}{2v^{3/2}}dv = -\frac{1}{x} dx
\ee
And this equation is separable and can be solved with integration!

\subsection*{Final Example}
Another example of the same class of problem.
\be
(ax + by + c) dx + (ex + fy + g dy) = 0
\ee
Where a,b,c,e,f,g are all constants.
But ax + by + c is not homogeneous because c is a lone constant (same with g).
Consider x = X + $\alpha$ and y = Y + $\beta$, dx = dX, and dy = dY.
Substitute in these definitions we find
\be
(aX + a\alpha + bY + b\beta + c) dX + (eX + e\alpha + fY + f\beta + g) dY = 0
\ee
We can find $\alpha$ and $\beta$,
\be
\begin{split}
    a\alpha + b\beta + c &= 0 \\
    e\alpha + f\beta + g &= 0 \\
\end{split}
\ee
This generates
\be
(aX + bY)dX + (eX + fY)dY = 0
\ee
Where we have a homogeneous equation, and we can solve using the methods from before.
\end{document}
